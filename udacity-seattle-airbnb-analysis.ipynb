{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [UDACITY] Seattle Airbnb Analysis\nThe Settle Airbnb Open Dateset is chosen for **UDACITY Project - Write a Data Science Blog Post**.\n\n6 steps of CRISP-DM (Cross-Industry Standard Process for Data Mining):\n1. Business Understanding\n1. Data Understanding\n1. Data Preparation\n1. Modelling\n1. Evaluation\n1. Deployment\n\n","metadata":{}},{"cell_type":"markdown","source":"# Business Understanding & Data Understanding\n\nAirbnb has been allowing visitors and hosts to expand their travel options and provide a more distinctive, personalised way of experiencing the world since 2008. Airbnb has evolved into a one-of-a-kind service that is used and recognised all over the world. The company's data analysis of millions of listings offered by Airbnb is a critical aspect. These millions of listings generate a lot of data, which can be analysed and used for a variety of purposes, including security, business decisions, understanding customer and provider (host) behaviour and performance on the platform, guiding marketing initiatives, and implementing innovative additional services, among others.\n\nThe **Seatlle Airbnb Open** Dataset catalogues homestay listings in Seattle, Washington from 01-2016 to 01-2017.\n\n\nThere are 3 subsets in the dataset:\n1. The pricing for each listing id for a certain day is described in **calendar.csv**.\n1. **listings.csv** contains a detailed description of each listing id, as well as review scores.\n1. For each individual listing id, **reviews.csv** gives detailed reviews.\n\nIn this project, we are going to use **calendar.csv** and **listings.csv** to answer 3 business questions:\n1. Which is the most busiest time in Settle?\n1. Where is the most crowdest in Settle?\n1. Price Prediction.\n\nFirst, let's import the data & revelant libraries needed for the analysis.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calendar = pd.read_csv('../input/seattle/calendar.csv')\nlistings = pd.read_csv('../input/seattle/listings.csv')\nreviews = pd.read_csv('../input/seattle/reviews.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Airbnb Busiest Times in Settle","metadata":{}},{"cell_type":"markdown","source":"Having a glance at the dataset. \nThere are 4 columns. \n\nThe **listing_id** and **price** columns are currently NOT in the correct datatype. We need to convert the data type of **listing_id** column into string and **price**'s into float.\n\nWe are going to extract **month** and **month_year** from the **date** column also.","metadata":{}},{"cell_type":"code","source":"calendar.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# listing_id\ncalendar['listing_id'] = calendar['listing_id'].astype(str)\n\n# month & month_year\ncalendar['month'] = pd.DatetimeIndex(calendar['date']).month\ncalendar['year'] = pd.DatetimeIndex(calendar['date']).year\ncalendar['month_year'] = pd.to_datetime(calendar['date']).dt.to_period('M')\n\n# price\ncalendar['price'] = calendar['price'].apply(lambda x: float((x[1:].replace(',',''))) if type(x) != float else x)\n\ncalendar.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"An Airbnb host can configure their listing's calendar to only be open for a few days or weeks every year.\nOther listings are available throughout the year (except for when it is already booked).\n\nThe price is available only when available = t.","metadata":{}},{"cell_type":"code","source":"check_f = calendar[(calendar['available'] == 'f') & (calendar['price'].notnull())].shape[0]\nprint('The number of rows where available = f and price is present is: {}  row(s)'.format(check_f))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only choose available = t where the price is available for all listing_id.\nThe calendar.csv subset is now ready. Let's pivot and plot some charts accordingly.","metadata":{}},{"cell_type":"code","source":"pivot_1 = pd.pivot_table(calendar[calendar['available'] == 't'], index='month', values=['price'], aggfunc={ 'price':np.mean})\npivot_1['month'] = pivot_1.index\n\npivot_2 = pd.pivot_table(calendar[calendar['available'] == 't'], index='month_year', values=['price'], aggfunc={'price':np.mean})\npivot_2['month_year'] = pivot_2.index\npivot_2['month_year'] = [str(x) for x in pivot_2['month_year']]\n\npivot_3 = pd.pivot_table(calendar, index='month', values=['listing_id'], columns=['available'], aggfunc={'listing_id': 'count'})\npivot_3['month'] = pivot_3.index\npivot_3['available_t'] = pivot_3.iloc[:,1]\npivot_3['available_f'] = pivot_3.iloc[:,0]\n\npivot_3['availibility_rate'] = pivot_3['available_t']/(pivot_3['available_t']+pivot_3['available_f'])\npivot_3 = pivot_3[['month','availibility_rate']].reset_index(drop=True)\npivot_3\n\nplt.figure(figsize=(30, 10))\ng = plt.GridSpec(2, 2) #Grid\n\n\nplt.subplot(g[0,0])\nplt.bar(pivot_3['month'], pivot_3['availibility_rate'])\nplt.xlabel('month')\nplt.xticks(pivot_3['month'])\nplt.ylabel('availibility_rate')\nplt.title('availibility_rate by month')\n\n\nplt.subplot(g[0,1])\nplt.bar(pivot_1['month'], pivot_1['price'])\nplt.xlabel('month')\nplt.xticks(pivot_1['month'])\nplt.ylabel('avg_price')\nplt.title('Avg price by month')\n\nplt.subplot(g[1,:])\nplt.bar(pivot_2['month_year'], pivot_2['price'])\nplt.xlabel('month_year')\nplt.xticks(pivot_2['month_year'])\nplt.ylabel('avg_price')\nplt.title('Avg price by month_year')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generally, the busiest times of the year is in the summer (the peak in July) when the price and the listingid_count are highest.","metadata":{}},{"cell_type":"markdown","source":"## 2. Where in Settle has the most Airbnb properties?","metadata":{}},{"cell_type":"markdown","source":"We are going to use listings.csv to answer the 2nd question. ","metadata":{}},{"cell_type":"code","source":"zip = listings['zipcode'].value_counts()\nzip = zip.to_frame().reset_index()\nzip = zip.rename({'index':'zipcode', 'zipcode':'listingid_count'}, axis=1)\nzip['zipcode'].astype('str')\n\n\nplt.figure(figsize = (20,10))\nplt.bar(zip['zipcode'], zip['listingid_count'])\nplt.xlabel('zipcode')\nplt.xticks(zip['zipcode'])\nplt.ylabel('listingid_count')\nplt.title('listingid_count by zipcode')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Top 5 areas which have the highest number of Airbnb properties in Seattle are: ')\nzip.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Price Prediction","metadata":{}},{"cell_type":"markdown","source":"listings - Detailed listings data for each listing, including 92 attributes. For price prediction, only relevant features are chosen:\n**'price','accommodates','bathrooms','bedrooms','beds','weekly_price','monthly_price','cleaning_fee', 'instant_bookable','reviews_per_month','cancellation_policy'**","metadata":{}},{"cell_type":"code","source":"print('The listings.csv subset has {} columns and {} rows.'.format(listings.shape[1], listings.shape[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"relevant_features = ['price','accommodates','bathrooms','bedrooms','beds','weekly_price','monthly_price','cleaning_fee', 'instant_bookable','reviews_per_month','cancellation_policy']\nlistings = listings[relevant_features]\nlistings.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preparation\n* String into Float for price-related columns\n* Missing values in numberic variables\n* Missing values in categorical variables","metadata":{}},{"cell_type":"markdown","source":"#### String into Float for price-related columns","metadata":{}},{"cell_type":"code","source":"listings['price'] = listings['price'].apply(lambda x: float((x[1:].replace(',',''))) if type(x) != float else x)\nlistings['weekly_price'] = listings['weekly_price'].apply(lambda x: float((x[1:].replace(',',''))) if type(x) != float else x)\nlistings['monthly_price'] = listings['monthly_price'].apply(lambda x: float((x[1:].replace(',',''))) if type(x) != float else x)\nlistings['cleaning_fee'] = listings['cleaning_fee'].apply(lambda x: float((x[1:].replace(',',''))) if type(x) != float else x)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The correlation coefficient is a number that ranges from -1 to 1.\n* A number near 0 indicates a lower association (exact 0 implying no correlation).\n* Closer to 1, the stronger the favourable association.\n* A negative correlation is stronger if the value is closer to -1.","metadata":{}},{"cell_type":"code","source":"print('Correlation among numeric variables: \\n')\n\nplt.figure(figsize=(14,10))\ncorr = listings.corr()\nprint(corr['price'], '\\n')\n\nprint('Present the result in heatmap: ')\nsns.heatmap(corr, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"listings sub-dataset still contains NaN values. In order to build a model, you must handle them. Otherwise,the fit model will break.","metadata":{}},{"cell_type":"code","source":"listings.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Missing values in numberic variables\n\nImputing objects into the matrix rather than dropping them is one method to start making predictions on these values.\n\nDrop the rows with missing response (price) values, then use the column's mean to estimate the values for all the other missing values.","metadata":{}},{"cell_type":"code","source":"num_vars = listings.select_dtypes(include=['int','float']).columns\nfor var in num_vars:\n    listings[var] = listings[var].fillna(listings[var].mean())\nlistings[num_vars].info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Missing values in categorical variables\n\nNaN values are frequently informative, but by leaving them as 0 in every column of your model, you are not capturing them. As a result, utilise **get dummies** to encode **NaN** values as their own dummy coded column using the **dummy na** option for categorical variables.","metadata":{}},{"cell_type":"code","source":"cat_bool_vars = listings.select_dtypes(include=['object','bool']).columns\ncat_bool_vars\nfor var in cat_bool_vars:\n    listings = pd.concat([listings.drop(var, axis=1), pd.get_dummies(listings[var], prefix=var, prefix_sep='_', drop_first=True)],\n                         axis=1)\n\ny = listings['price']\nX = listings.drop(columns = ['price'], inplace=False)\nX.info(verbose=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"markdown","source":"4 steps to build a model:\n* Instantiate your linear model using normalized data\n* Fit your model on the training data\n* Predict using the test data\n* Score the model on the test\n\nThe fit method in sklearn breaks due to NAN values.\nTo assure the model extends well to new data, we must creat a train test split.\nTo assure the same train and test split will occure for different users, random_state is set with a fixed number.\n\n","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nlm_model = LinearRegression(normalize = True)\nlm_model.fit(X_train, y_train)\ny_test_predict = lm_model.predict(X_test)\ny_train_predict = lm_model.predict(X_train)\ntest_score = r2_score(y_test, y_test_predict)\ntrain_score = r2_score(y_train, y_train_predict)\n\nprint('test_score: ',test_score)\nprint('train_score: ', train_score)\nif abs(test_score/train_score) > 0.8:\n    print('The model is not overfitted.')\nelse:\n    print('Need to improve the model.')\nprint('The r-squared score for the model is {} on {} values.'.format(test_score, len(y_test)),'\\n')\n\n\ncoef_df = pd.DataFrame()\ncoef_df['feature'] = X_train.columns\ncoef_df['coef'] = lm_model.coef_\ncoef_df['abs_coef'] = np.abs(lm_model.coef_)\ncoef_df.sort_values(by=['abs_coef'], ascending=False)\nprint('Top 20 featutes which have the most impact on price: \\n', coef_df, '\\n')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\nThe business goes well in the Summer in general. Top 5 areas which have the highest number of Airbnb properties in Seattle are: 98122, 98103, 98102, 98105, 98109. Among the chosen features, accommodates has the most impact on the price.","metadata":{}}]}